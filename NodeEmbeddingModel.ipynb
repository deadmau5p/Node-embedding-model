{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NodeEmbeddingModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MqZQXM3Eg-O0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from torch.optim import SGD\n",
        "import networkx as nx\n",
        "import random\n",
        "from torch.optim import SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.karate_club_graph()\n",
        "number_of_nodes = len(G.nodes)\n",
        "pos_edge_list = list(G.edges)\n",
        "pos_edge_index = torch.tensor(pos_edge_list).type(torch.LongTensor).T\n",
        "neg_edge_index = torch.tensor(random.sample(list(nx.non_edges(G)), 78)).type(torch.LongTensor).T\n",
        "\n",
        "init_embeddings = nn.Embedding(num_embeddings=number_of_nodes, embedding_dim=16)\n",
        "torch.manual_seed(1)\n",
        "shape = init_embeddings.weight.data.shape\n",
        "init_embeddings.weight.data = torch.rand(shape)"
      ],
      "metadata": {
        "id": "oksoBljBhg5C"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred, label):\n",
        "  accu = 0.0\n",
        "  pred_1 = torch.round(pred)\n",
        "  for i in range(pred.shape[0]):\n",
        "    if int(pred_1[i]) == int(label[i]):\n",
        "      accu += 1\n",
        "  accu /= pred.shape[0]\n",
        "  accu = round(accu, 4)\n",
        "  return accu\n",
        "\n",
        "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
        "  epochs = 1000\n",
        "  learning_rate = 0.5\n",
        "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  for i in range(epochs):\n",
        "    optimizer.zero_grad\n",
        "    embeddings = emb(train_edge)\n",
        "    dot = torch.mul(embeddings[0], embeddings[1]).sum(1)\n",
        "    result = sigmoid(dot)\n",
        "    loss = loss_fn(result, train_label)\n",
        "    print(i, \": Loss:\", loss.item(), \"Accuracy:\", accuracy(result, train_label))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "\n",
        "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "\n",
        "train(init_embeddings, loss_fn, sigmoid, train_label, train_edge)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31aIy6FFpc1P",
        "outputId": "34f17981-9d6f-403b-871b-4c139f8de29e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "1 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "2 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "3 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "4 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "5 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "6 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "7 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "8 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "9 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "10 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "11 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "12 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "13 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "14 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "15 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "16 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "17 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "18 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "19 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "20 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "21 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "22 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "23 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "24 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "25 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "26 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "27 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "28 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "29 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "30 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "31 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "32 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "33 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "34 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "35 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "36 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "37 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "38 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "39 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "40 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "41 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "42 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "43 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "44 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "45 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "46 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "47 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "48 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "49 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "50 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "51 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "52 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "53 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "54 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "55 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "56 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "57 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "58 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "59 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "60 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "61 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "62 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "63 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "64 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "65 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "66 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "67 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "68 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "69 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "70 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "71 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "72 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "73 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "74 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "75 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "76 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "77 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "78 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "79 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "80 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "81 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "82 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "83 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "84 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "85 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "86 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "87 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "88 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "89 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "90 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "91 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "92 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "93 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "94 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "95 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "96 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "97 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "98 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "99 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "100 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "101 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "102 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "103 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "104 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "105 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "106 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "107 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "108 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "109 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "110 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "111 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "112 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "113 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "114 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "115 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "116 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "117 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "118 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "119 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "120 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "121 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "122 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "123 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "124 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "125 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "126 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "127 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "128 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "129 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "130 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "131 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "132 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "133 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "134 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "135 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "136 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "137 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "138 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "139 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "140 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "141 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "142 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "143 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "144 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "145 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "146 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "147 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "148 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "149 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "150 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "151 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "152 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "153 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "154 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "155 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "156 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "157 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "158 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "159 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "160 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "161 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "162 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "163 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "164 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "165 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "166 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "167 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "168 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "169 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "170 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "171 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "172 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "173 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "174 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "175 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "176 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "177 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "178 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "179 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "180 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "181 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "182 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "183 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "184 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "185 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "186 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "187 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "188 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "189 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "190 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "191 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "192 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "193 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "194 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "195 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "196 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "197 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "198 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "199 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "200 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "201 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "202 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "203 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "204 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "205 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "206 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "207 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "208 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "209 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "210 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "211 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "212 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "213 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "214 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "215 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "216 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "217 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "218 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "219 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "220 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "221 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "222 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "223 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "224 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "225 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "226 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "227 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "228 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "229 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "230 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "231 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "232 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "233 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "234 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "235 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "236 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "237 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "238 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "239 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "240 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "241 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "242 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "243 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "244 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "245 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "246 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "247 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "248 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "249 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "250 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "251 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "252 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "253 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "254 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "255 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "256 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "257 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "258 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "259 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "260 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "261 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "262 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "263 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "264 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "265 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "266 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "267 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "268 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "269 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "270 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "271 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "272 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "273 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "274 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "275 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "276 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "277 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "278 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "279 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "280 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "281 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "282 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "283 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "284 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "285 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "286 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "287 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "288 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "289 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "290 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "291 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "292 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "293 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "294 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "295 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "296 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "297 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "298 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "299 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "300 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "301 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "302 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "303 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "304 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "305 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "306 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "307 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "308 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "309 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "310 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "311 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "312 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "313 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "314 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "315 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "316 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "317 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "318 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "319 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "320 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "321 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "322 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "323 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "324 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "325 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "326 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "327 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "328 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "329 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "330 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "331 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "332 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "333 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "334 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "335 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "336 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "337 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "338 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "339 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "340 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "341 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "342 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "343 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "344 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "345 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "346 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "347 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "348 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "349 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "350 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "351 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "352 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "353 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "354 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "355 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "356 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "357 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "358 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "359 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "360 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "361 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "362 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "363 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "364 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "365 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "366 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "367 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "368 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "369 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "370 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "371 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "372 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "373 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "374 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "375 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "376 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "377 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "378 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "379 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "380 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "381 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "382 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "383 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "384 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "385 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "386 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "387 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "388 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "389 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "390 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "391 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "392 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "393 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "394 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "395 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "396 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "397 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "398 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "399 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "400 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "401 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "402 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "403 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "404 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "405 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "406 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "407 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "408 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "409 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "410 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "411 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "412 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "413 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "414 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "415 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "416 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "417 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "418 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "419 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "420 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "421 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "422 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "423 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "424 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "425 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "426 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "427 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "428 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "429 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "430 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "431 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "432 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "433 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "434 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "435 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "436 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "437 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "438 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "439 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "440 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "441 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "442 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "443 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "444 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "445 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "446 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "447 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "448 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "449 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "450 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "451 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "452 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "453 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "454 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "455 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "456 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "457 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "458 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "459 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "460 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "461 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "462 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "463 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "464 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "465 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "466 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "467 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "468 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "469 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "470 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "471 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "472 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "473 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "474 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "475 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "476 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "477 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "478 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "479 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "480 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "481 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "482 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "483 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "484 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "485 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "486 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "487 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "488 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "489 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "490 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "491 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "492 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "493 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "494 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "495 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "496 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "497 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "498 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "499 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "500 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "501 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "502 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "503 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "504 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "505 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "506 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "507 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "508 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "509 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "510 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "511 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "512 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "513 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "514 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "515 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "516 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "517 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "518 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "519 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "520 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "521 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "522 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "523 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "524 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "525 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "526 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "527 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "528 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "529 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "530 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "531 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "532 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "533 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "534 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "535 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "536 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "537 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "538 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "539 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "540 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "541 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "542 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "543 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "544 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "545 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "546 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "547 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "548 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "549 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "550 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "551 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "552 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "553 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "554 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "555 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "556 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "557 : Loss: 31.41025733947754 Accuracy: 0.6859\n",
            "558 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "559 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "560 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "561 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "562 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "563 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "564 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "565 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "566 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "567 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "568 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "569 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "570 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "571 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "572 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "573 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "574 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "575 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "576 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "577 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "578 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "579 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "580 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "581 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "582 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "583 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "584 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "585 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "586 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "587 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "588 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "589 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "590 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "591 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "592 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "593 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "594 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "595 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "596 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "597 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "598 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "599 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "600 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "601 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "602 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "603 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "604 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "605 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "606 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "607 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "608 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "609 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "610 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "611 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "612 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "613 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "614 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "615 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "616 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "617 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "618 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "619 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "620 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "621 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "622 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "623 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "624 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "625 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "626 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "627 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "628 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "629 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "630 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "631 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "632 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "633 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "634 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "635 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "636 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "637 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "638 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "639 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "640 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "641 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "642 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "643 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "644 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "645 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "646 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "647 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "648 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "649 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "650 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "651 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "652 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "653 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "654 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "655 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "656 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "657 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "658 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "659 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "660 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "661 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "662 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "663 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "664 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "665 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "666 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "667 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "668 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "669 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "670 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "671 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "672 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "673 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "674 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "675 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "676 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "677 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "678 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "679 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "680 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "681 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "682 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "683 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "684 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "685 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "686 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "687 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "688 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "689 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "690 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "691 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "692 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "693 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "694 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "695 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "696 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "697 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "698 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "699 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "700 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "701 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "702 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "703 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "704 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "705 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "706 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "707 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "708 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "709 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "710 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "711 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "712 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "713 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "714 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "715 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "716 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "717 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "718 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "719 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "720 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "721 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "722 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "723 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "724 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "725 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "726 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "727 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "728 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "729 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "730 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "731 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "732 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "733 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "734 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "735 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "736 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "737 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "738 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "739 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "740 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "741 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "742 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "743 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "744 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "745 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "746 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "747 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "748 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "749 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "750 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "751 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "752 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "753 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "754 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "755 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "756 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "757 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "758 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "759 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "760 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "761 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "762 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "763 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "764 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "765 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "766 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "767 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "768 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "769 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "770 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "771 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "772 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "773 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "774 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "775 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "776 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "777 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "778 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "779 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "780 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "781 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "782 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "783 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "784 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "785 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "786 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "787 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "788 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "789 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "790 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "791 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "792 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "793 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "794 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "795 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "796 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "797 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "798 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "799 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "800 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "801 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "802 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "803 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "804 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "805 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "806 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "807 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "808 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "809 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "810 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "811 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "812 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "813 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "814 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "815 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "816 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "817 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "818 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "819 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "820 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "821 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "822 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "823 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "824 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "825 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "826 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "827 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "828 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "829 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "830 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "831 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "832 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "833 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "834 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "835 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "836 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "837 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "838 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "839 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "840 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "841 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "842 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "843 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "844 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "845 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "846 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "847 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "848 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "849 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "850 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "851 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "852 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "853 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "854 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "855 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "856 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "857 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "858 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "859 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "860 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "861 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "862 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "863 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "864 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "865 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "866 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "867 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "868 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "869 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "870 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "871 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "872 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "873 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "874 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "875 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "876 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "877 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "878 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "879 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "880 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "881 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "882 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "883 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "884 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "885 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "886 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "887 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "888 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "889 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "890 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "891 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "892 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "893 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "894 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "895 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "896 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "897 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "898 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "899 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "900 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "901 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "902 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "903 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "904 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "905 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "906 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "907 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "908 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "909 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "910 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "911 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "912 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "913 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "914 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "915 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "916 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "917 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "918 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "919 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "920 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "921 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "922 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "923 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "924 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "925 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "926 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "927 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "928 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "929 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "930 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "931 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "932 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "933 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "934 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "935 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "936 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "937 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "938 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "939 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "940 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "941 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "942 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "943 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "944 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "945 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "946 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "947 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "948 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "949 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "950 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "951 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "952 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "953 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "954 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "955 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "956 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "957 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "958 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "959 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "960 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "961 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "962 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "963 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "964 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "965 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "966 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "967 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "968 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "969 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "970 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "971 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "972 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "973 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "974 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "975 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "976 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "977 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "978 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "979 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "980 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "981 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "982 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "983 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "984 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "985 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "986 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "987 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "988 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "989 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "990 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "991 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "992 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "993 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "994 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "995 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "996 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "997 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "998 : Loss: 30.769229888916016 Accuracy: 0.6923\n",
            "999 : Loss: 30.769229888916016 Accuracy: 0.6923\n"
          ]
        }
      ]
    }
  ]
}